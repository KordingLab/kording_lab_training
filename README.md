Kording Lab Training Session
======================

Repository for training session by Titipat Achakulvisut at Kording's Lab.

## Session 1

Presentation covers how to get up running [Spark](http://spark.apache.org/) on Quest (Northwestern Computing Clusters). Notebook goes through Map Reduce algorithm where we provide an example on a simple text file. We then implement stochatic gradient descent to train Logistic Regression in order to classify MNIST dataset. Here is a [link](http://klab.smpp.northwestern.edu/wiki/images/9/9b/Big_data_klab.pdf) to a presentation file.


## Session 2

This tutorial is one of the Deep learning tutorial by Kording lab.
In this presentation, we will go through simple neural network architecture and math behind it including forward propagation and back propagation (ref. Andrew Ng lecture).
We will then code the forward propagation and back propagation algorithm and test it on MNIST examples. If we have time, we will go through existing
python packages that implement Neural Network (e.g. [`Lasagne`](https://github.com/Lasagne/Lasagne), [`scikit-neuralnetwork`](https://github.com/aigamedev/scikit-neuralnetwork), [`pybrain`](http://pybrain.org/), [`nolearn`](https://github.com/dnouri/nolearn).

## Session 3

In this session, we will go over Recurrent Neural Network (RNN) and its application in Natural Language Processing (NLP). 
We'll go through architechure of the RNN also a bit of Convolutional Neural Network (CNN) presented by Pavan. 
We use [CS224d: Deep Learning for Natural Language Processing](http://cs224d.stanford.edu/syllabus.html) as main materials. 
After the lecture, We will go over implementing RNN and CNN using TensorFlow for application in NLP.
